{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tika/lib/python3.13/site-packages/tika/__init__.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__('pkg_resources').declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tika\n",
    "from tika import parser\n",
    "\n",
    "tika.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TIKA_SERVER_ENDPOINT\"] = \"http://localhost:9998\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(file_path):\n",
    "\n",
    "    def preprocess_content(content):\n",
    "        if content:\n",
    "            content = content.replace(\"\\\\n\", \" \")\n",
    "            return content.strip()\n",
    "        return content\n",
    "        \n",
    "    parsed = parser.from_file(file_path)\n",
    "    content = preprocess_content(parsed[\"content\"])\n",
    "    display(parsed[\"metadata\"])\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = [\n",
    "    \"docx\",\n",
    "    \"doc\",\n",
    "    \"pdf\",\n",
    "    \"hwp\",\n",
    "    # \"hwpx\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing sample.docx...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cp:revision': '2',\n",
       " 'extended-properties:AppVersion': '16.0000',\n",
       " 'meta:paragraph-count': '12',\n",
       " 'meta:word-count': '970',\n",
       " 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.microsoft.ooxml.OOXMLParser'],\n",
       " 'X-TIKA:content_handler': 'ToTextContentHandler',\n",
       " 'extended-properties:Company': '',\n",
       " 'dcterms:created': '2022-09-19T14:35:00Z',\n",
       " 'meta:line-count': '46',\n",
       " 'dcterms:modified': '2022-09-19T14:36:00Z',\n",
       " 'meta:character-count': '5535',\n",
       " 'meta:character-count-with-spaces': '6493',\n",
       " 'extended-properties:TotalTime': '1',\n",
       " 'Content-Length': '33031',\n",
       " 'Content-Type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n",
       " 'extended-properties:Application': 'Microsoft Office Word',\n",
       " 'meta:last-author': 'sckimosu@outlook.kr',\n",
       " 'xmpTPg:NPages': '3',\n",
       " 'resourceName': \"b'sample.docx'\",\n",
       " 'extended-properties:Template': 'Normal.dotm',\n",
       " 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.microsoft.ooxml.OOXMLParser'],\n",
       " 'extended-properties:DocSecurityString': 'None',\n",
       " 'X-TIKA:parse_time_millis': '270',\n",
       " 'X-TIKA:embedded_depth': '0',\n",
       " 'meta:page-count': '3',\n",
       " 'dc:publisher': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사전학습 BERT 기반 미세 조정 기법별 감정 분류 성능 평가\n",
      "홍성규, 김상철*\n",
      "국민대학교, *국민대학교\n",
      "hsung951027@kookmin[footnoteRef:2].ac.kr, *sckim7@kookmin.ac.kr [2:  *: 교신저자] \n",
      "\n",
      "\n",
      "Evaluation of sentimental classification performace \n",
      "by fine-tuning methods based on Pre-trained BERT\n",
      "Hong Sung Kyu, Kim Sang Chul*\n",
      "Kookmin Univ., *Kookmin Univ.\n",
      "\n",
      "요 약 \n",
      "\n",
      "BERT(Bidirectional Encoder Representations from Transformers)는 2017년 구글에서 발표한 Transformer 기반의 양방향 문맥을 학습할 수 있도록 고안된 언어모델이다. 오늘날 언어모델의 규모가 커짐에 따라, 현실적으로 리소스 및 시간 등 학습하는데에 어려움이 수반하고 있다. 이러한 문제를 해결하기 위해 사전학습된 언어를 Fine-tuning하는 과정에서 파라미터를 경량화 시키기 위해 대표적으로 AdapterFusion과 LoRA와 같은 Fully fine-tuning을 대체하는 방법이 연구되고 있다. 본 논문에서는 새로운 Fine-tuning 기법들을 BERT에 적용하며, 학습 시간 및 정확도에 어느정도 영향을 끼치는지 연구한다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ⅰ. 서 론 \n",
      "2017년 구글에서 Transformer 구조[1]를 제안하면서 NLP영역에는 기존의 RNN 혹은 LSTM과 같은 셀들을 대체하는 새로운 패러다임이 시작되었다. 이러한 Transformer기반의 모델들은 오늘날까지 발전해오면서 OpenAI에서 발표한 GPT(Generative Pre–Training)[3]과 구글에서 발표한 BERT(Bidirectional Encoder Representations from Transformers)가 있다. 하지만, 그 밖에도 더욱 모델 파라미터의 규모가 커질수록 학습은 점차 어려워진다[5]. 그러므로, 모델의 전체 파라미터가 아닌 일부 파라미터만 재학습 시킬 수 있도록 새로운 Fine-tuning 기법들이 연구되고 있다. 대표적으로, Multi-task transfer learning에 최적화하기 위한 AdapterFusion과 Rank factorization을 활용한 LoRA가 있다. 본 논문에서는 두 가지 Fine-tuning 기법들을 BERT에 적용한다.\n",
      "\n",
      "Ⅱ. BERT (Bidirectional Encoder Representations from Transformers)\n",
      "BERT와 같은 Transformer 기반의 사전학습 언어모델(Pre-trained Language Model)은 주로 준지도 학습 방식(Semi-Supervised learning)을 따르게 된다. 이는 모델에 대량의 말뭉치(Corpus)를 비지도 학습(Unsupervised learning)을 먼저 한 후에, 해결하고자 하는 태스크에 적합한 데이터를 통해 미세 조정(Fine-tuning) 과정에서 지도 학습(Supervised learning)을 한다. BERT는 GPT와는 다르게 양방향으로 텍스트의 representation을 학습하도록 설계되었다[2].\n",
      "\n",
      "\n",
      " (1) BERT의 입력\n",
      "BERT의 입력은 세 가지 임베딩을 합한 결과를 입력받는다. 첫 번째는 각 토큰을 벡터 Representation인 Token embedding이다. 두 번째는 Positional embedding이다. Transformer 기반 모델은 RNN(Recurrence Neural Network) 처럼 입력을 순차적으로 받지 않기 때문에 각 토큰의 위치 정보를 부여해주어야 한다. 세 번째는 Segment embedding이다. 문장이 여러개 입력될 경우, 각 문장을 구분하기 위해서 Segment embedding이 사용된다.\n",
      "\n",
      " (2) BERT 사전학습 과정\n",
      "BERT의 사전학습 과정은 Unsupervised 혹은 Self-supervised learning으로, 대표적으로 두 가지이다. 첫 번째는 MLM(Masked Language Model) 이다. BERT라는 이름에서 알 수 있듯이 Denosing AutoEncoder의 역할을 한다. 그 이유는 입력 토큰에 대해 랜덤하게 마스킹 처리된 토큰들을 예측하기 때문이다. 이 과정에서 마스킹 처리를 노이즈로 해석하면 DAE로써 해석이 가능하다. 두 번째는 NSP(Next Sentence Prediction) 이다. 한 쌍의 문장이 들어왔을 때, 두 문장이 다음 문장인지 예측하는 과정이다. 이러한 태스크는 문장 전체에 대한 이해를 학습한다.\n",
      "\n",
      " (3) BERT 미세조정 과정\n",
      "BERT의 Fine-tuning 단계는 매우 단순하다. 이미 사전학습이 되어 있는 BERT 모델의 최상단에 해결하고자 하는 태스크에 적절한 Head를 최상단에 배치하면 된다. 해당 과정은 사전학습 과정보다 적은 epoch이 소요되기 때문에, 상대적으로 적은 리소스로 학습이 가능하다. huggingface(https://huggingface.co/)에 배포되어 있는 사전학습된 모델을 Python 패키지인 transformers를 통해 불러올 수 있다.\n",
      "\n",
      "Ⅲ. Fine-tuning Approach 1 : AdapterFusion\n",
      "최근 언어모델의 파라미터 규모가 점점 커짐에 따라 Fine-tuning이 현실적으로 불가능해지고 있다. 계산을 위한 많은 컴퓨팅 리소스 혹은 시간이 소요되기 때문이다. 그 뿐만 아니라, 순차적 미세조정(Sequential fine-tuning) 혹은 다중-태스크 학습(Multi-task learning)과 같은 전이 학습에도 어려움이 있다. 이러한 문제를 해결하기 위해 2021년 Jonas pfeiffer에 의해 AdapterFusion이라는 대안이 제시되었다[4]. AdapterFusion는 Transformer 기반 모델에 적용할 수 있으며, 매커니즘은 크게 두 단계로 구성되어 있다. 첫 번째로,  Transformer 레이어에 Task-specific adapter를 주입한다. 두 번째는 Fusion 레이어를 적용하여, 장착된 Adapter들에 Attention 매커니즘을 적용하여 현재 모델의 태스크에 적합한 Adapter에 가중치를 부여하여 활성화 시킨다. AdapterFusion은 기존 Transformer 기반의 언어모델의 Fully fine-tuning을 하지않고, 모델의 가중치를 동결(Freeze)한 다음에, Adapter와 Fusion 레이어에 대한 가중치만 학습하여 매우 적은 가중치(Single-Task adapter 기준, Pre-trained model의 3.6%의 가중치)만을 학습한다. Adapter가 적용된 모델은 AdapterHub(https://adapterhub.ml/)에서 Python 패키지인 adapter-transformers를 통해 불러올 수 있다.\n",
      "\n",
      "Ⅳ. Fine-tuning Approach 1 : LoRA\n",
      "LoRA(Low-Rank Adaptation)은 2020년 Aghajanyan의 Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning 논문으로부터 영감은 받아 제안된 논문이다. LoRA의 핵심은 에 Rank factorization을 적용하여 로 수식을 변경하는 것이다. (, ) 여기서, 는 사전학습된 가중치 행렬을 의미하고, 는 누적된 그레디언트의 업데이트를 의미한다. 그리고, 을 동결한 상태에서, 와 만 업데이트하기 때문에 기존 Fully fine-tuning보다 적은 파라미터로 학습할 수 있게 된다. LoRA는 AdapterHub가 아닌, 마이크로소프트에서 공개한 깃허브 레포지토리(https://github.com/microsoft/LoRA)에서 적용이 가능하다. 현재 LoRA는 Pytorch 프레임워크에서만 적용 가능하며, 사용가능한 레이어는 nn.Linear, nn.Embedding, nn.Conv2d가 있다.\n",
      "\n",
      "Ⅴ. 실험과정\n",
      "실험을 위해 nsmc(네이버 영화 리뷰 데이터셋 : https://github.com/e9t/nsmc)를 통한 감정분류(Sentimental Classification)테스크를 진행했다. 실험을 진행한 모델은 세 가지로 다음과 같다.\n",
      "\n",
      "(1) bert-base-multilingual-cased\n",
      "(2) bert-base-multilingual-cased + ko/wiki@ukp pfeiffer adapter\n",
      "(3) Bert-base-multilingual-cased + LoRA linear layers\n",
      "\n",
      "실험은 Tesla V100 GPU에서 15만건의 학습 데이터를 5만건씩 줄여가면서 하이퍼 파라미터를 수정하면서 진행했다. 학습을 위한 하이퍼 파라미터는 AdamW 옵티마이저와 learning rate은 , epsilon은 , epochs는 4로 지정했다. 성능 평가 지표는 정확도(Accuracy)를 사용했으며, LoRA의 하이퍼 파라미터는 r를 15만건의 데이터를 학습한 케이스에서만 튜닝했다.\n",
      "\n",
      "\n",
      "\n",
      "Ⅵ. 실험결과\n",
      "\t\n",
      "\tTraining time per epoch (mm:ss)\n",
      "\tTest accuracy\n",
      "\tPrecision\n",
      "\tRecall\n",
      "\tF1-\n",
      "Score\n",
      "\n",
      "\tVanilla\n",
      "\t17:01 ~ 17:04\n",
      "\t0.871\n",
      "\t0.864\n",
      "\t0.882\n",
      "\t0.869\n",
      "\n",
      "\tAdapterFusion\n",
      "\t12:29 ~ 12:30\n",
      "\t0.858\n",
      "\t0.856\n",
      "\t0.863\n",
      "\t0.855\n",
      "\n",
      "\tLoRA (r=64)\n",
      "\t10:59 ~ 11:01\n",
      "\t0.726\n",
      "\t0.745\n",
      "\t0.692\n",
      "\t0.711\n",
      "\n",
      "\tLoRA (r=32)\n",
      "\t10:52 ~ 10:53\n",
      "\t0.722\n",
      "\t0.741\n",
      "\t0.688\n",
      "\t0.707\n",
      "\n",
      "\tLoRA (r=16)\n",
      "\t10:50 ~ 10:51\n",
      "\t0.716\n",
      "\t0.751\n",
      "\t0.651\n",
      "\t0.691\n",
      "\n",
      "\t표 1 15만건에 대한 학습 결과\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\tTraining time per epoch (mm:ss)\n",
      "\tTest accuracy\n",
      "\tPrecision\n",
      "\tRecall\n",
      "\tF1-Score\n",
      "\n",
      "\tVanilla\n",
      "\t11:19 ~ 11:28\n",
      "\t0.864\n",
      "\t0.859\n",
      "\t0.873\n",
      "\t0.862\n",
      "\n",
      "\tAdapterFusion\n",
      "\t08:20 ~ 08:21\n",
      "\t0.850\n",
      "\t0.849\n",
      "\t0.853\n",
      "\t0.847\n",
      "\n",
      "\tLoRA (r=64)\n",
      "\t07:19 ~ 07:21\n",
      "\t0.683\n",
      "\t0.692\n",
      "\t0.662\n",
      "\t0.670\n",
      "\n",
      "\t표 2 10만건에 대한 학습 결과\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\tTraining time per epoch (mm:ss)\n",
      "\tTest accuracy\n",
      "\tPrecision\n",
      "\tRecall\n",
      "\tF1-Score\n",
      "\n",
      "\tVanilla\n",
      "\t05:40 ~ 05:42\n",
      "\t0.848\n",
      "\t0.840\n",
      "\t0.863\n",
      "\t0.847\n",
      "\n",
      "\tAdapterFusion\n",
      "\t04:10 ~ 04:12\n",
      "\t0.830\n",
      "\t0.836\n",
      "\t0.824\n",
      "\t0.826\n",
      "\n",
      "\tLoRA (r=64)\n",
      "\t03:40\n",
      "\t0.634\n",
      "\t0.620\n",
      "\t0.706\n",
      "\t0.653\n",
      "\n",
      "\t표 3 5만건에 대한 학습 결과\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "실험은 학습 문장 15만건중 5만건씩 줄여가며 진행했다. 15만건의 문장에 대해 실험을 진행할 때, LoRA의 r값이 줄어들수록 가중치 행렬의 크기가 줄어들어 정확도가 낮아지는 것을 확인했다. Vanilla 기법은 Fully fine-tuning 기법을 의미하며, 다른 기법대비 학습하는 파라미터의 수가 많아 정확도는 높지만, 학습 시간은 상대적으로 많이 소요된다. 그리고, 학습 데이터의 양이 줄어들수록 AdapterFusion과 LoRA와 같은 Fine-tuning 기법들의 학습 시간 감소 비율이 줄어든 것을 확인할 수 있다.\n",
      "\n",
      "\n",
      "Ⅶ. 결론\n",
      "AdapterFusion과 LoRA를 적용했을 때 학습 속도는 줄어들지만, 정확도는 Fully fine-tuning을 상회하지 못한다. 이는 절대적으로 학습해야하는 파라미터 수가 줄어들어 나타난다고 추측한다. 본 논문에서 언급한 Fine-tuning 기법들은 학습 데이터셋의 수가 많고, 모델의 사이즈가 큰 경우에 효과적이다. 최근 화두가 되고 있는 준지도 학습 기반 딥러닝 모델들의 규모가 커짐에 따라 Fine-tuning 기법들은 필수적인 요소가 될 것이다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ACKNOWLEDGMENT \n",
      "\"본 연구는 2022년 과학기술정보통신부 및 정보통신기획평가원의 SW중심대학사업의 연구결과로 수행되었으며 (2022-0-00964), 또한 과학기술정보통신부 및 정보통신기획평가원의 대학ICT연구센터육성지원사업의 연구결과로 수행되었음 (IITP-2022-2018-0-01396)\n",
      "\n",
      "참 고 문 헌 \n",
      "[1] Ashish Vaswani, “Attention Is All You Need”, 2017\n",
      "[2] Jacob Devlin, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”, 2018\n",
      "[3] Tom B. Brown, “Language Models are Few-Shot Learners”, 2020\n",
      "[4] Jonas pfeiffer, “AdapterFusion: Non-Destructive Task Composition for Transfer Learning”, 2021\n",
      "[5] Edward Hu, “LoRA: Low-Rank Adaptation Of Large Language Models”, 2021\n",
      "\n",
      "Parsing sample.doc...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cp:revision': '1',\n",
       " 'meta:word-count': '4361',\n",
       " 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.microsoft.OfficeParser',\n",
       "  'org.apache.tika.parser.image.ImageParser',\n",
       "  'org.apache.tika.parser.ocr.TesseractOCRParser',\n",
       "  'org.apache.tika.parser.microsoft.WMFParser',\n",
       "  'org.apache.tika.parser.EmptyParser'],\n",
       " 'X-TIKA:content_handler': ['ToTextContentHandler',\n",
       "  'ToTextContentHandler',\n",
       "  'ToTextContentHandler',\n",
       "  'ToTextContentHandler'],\n",
       " 'dc:creator': 'yanqing',\n",
       " 'extended-properties:Company': 'IEEE',\n",
       " 'meta:print-date': '2003-06-06T18:50:00Z',\n",
       " 'dcterms:created': '2007-10-10T22:44:00Z',\n",
       " 'dcterms:modified': '2007-10-10T22:59:00Z',\n",
       " 'meta:character-count': '24863',\n",
       " 'dc:title': '\\uf020',\n",
       " 'extended-properties:TotalTime': '1800000000',\n",
       " 'Content-Length': '98304',\n",
       " 'Content-Type': ['application/msword',\n",
       "  'image/png',\n",
       "  'image/wmf',\n",
       "  'image/wmf',\n",
       "  'application/vnd.ms-equation',\n",
       "  'application/vnd.ms-equation'],\n",
       " 'dc:subject': 'IEEE Transactions on Magnetics ',\n",
       " 'extended-properties:Application': 'Microsoft Word 9.0',\n",
       " 'meta:last-author': 'yanqing',\n",
       " 'xmpTPg:NPages': '1',\n",
       " 'resourceName': [\"b'sample.doc'\",\n",
       "  'image3.png',\n",
       "  'image1.wmf',\n",
       "  'image2.wmf',\n",
       "  '_1079260227.unknown',\n",
       "  '_1079260234.unknown'],\n",
       " 'X-TIKA:origResourceName': 'C:\\\\Yanqing\\\\IEEE VES 2007\\\\doc Template.doc',\n",
       " 'extended-properties:Template': 'Sample doc paper',\n",
       " 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.microsoft.OfficeParser',\n",
       "  ['org.apache.tika.parser.DefaultParser',\n",
       "   'org.apache.tika.parser.image.ImageParser',\n",
       "   'org.apache.tika.parser.ocr.TesseractOCRParser'],\n",
       "  ['org.apache.tika.parser.DefaultParser',\n",
       "   'org.apache.tika.parser.microsoft.WMFParser'],\n",
       "  ['org.apache.tika.parser.DefaultParser',\n",
       "   'org.apache.tika.parser.microsoft.WMFParser'],\n",
       "  'org.apache.tika.parser.EmptyParser',\n",
       "  'org.apache.tika.parser.EmptyParser'],\n",
       " 'X-TIKA:parse_time_millis': ['1640', '1305', '71', '6', '1', '0'],\n",
       " 'X-TIKA:embedded_depth': ['0', '1', '1', '1', '1', '1'],\n",
       " 'meta:page-count': '1',\n",
       " 'Transparency Alpha': 'none',\n",
       " 'PLTE PLTEEntry': ['index=0, red=0, green=0, blue=0',\n",
       "  'index=1, red=255, green=255, blue=255'],\n",
       " 'X-TIKA:embedded_id_path': ['/1', '/2', '/3', '/4', '/5'],\n",
       " 'tiff:ImageLength': '1571',\n",
       " 'Compression CompressionTypeName': 'deflate',\n",
       " 'Chroma Palette PaletteEntry': ['index=0, red=0, green=0, blue=0',\n",
       "  'index=1, red=255, green=255, blue=255'],\n",
       " 'Data BitsPerSample': '1 1 1',\n",
       " 'Data PlanarConfiguration': 'PixelInterleaved',\n",
       " 'Dimension VerticalPixelSize': '0.042333417',\n",
       " 'IHDR': 'width=2070, height=1571, bitDepth=1, colorType=Palette, compressionMethod=deflate, filterMethod=adaptive, interlaceMethod=none',\n",
       " 'Chroma ColorSpaceType': 'RGB',\n",
       " 'tiff:BitsPerSample': '1 1 1',\n",
       " 'X-TIKA:embedded_id': ['1', '2', '3', '4', '5'],\n",
       " 'height': '1571',\n",
       " 'imagereader:NumImages': '1',\n",
       " 'gAMA': '45448',\n",
       " 'X-TIKA:final_embedded_resource_path': ['/image3.png',\n",
       "  '/image1.wmf',\n",
       "  '/image2.wmf',\n",
       "  '/_1079260227.unknown',\n",
       "  '/_1079260234.unknown'],\n",
       " 'pHYs': 'pixelsPerUnitXAxis=23622, pixelsPerUnitYAxis=23622, unitSpecifier=meter',\n",
       " 'Chroma Gamma': '0.45448',\n",
       " 'Dimension PixelAspectRatio': '1.0',\n",
       " 'Compression NumProgressiveScans': '1',\n",
       " 'Content-Type-Parser-Override': 'image/ocr-png',\n",
       " 'Dimension HorizontalPixelSize': '0.042333417',\n",
       " 'Chroma BlackIsZero': 'true',\n",
       " 'Compression Lossless': 'true',\n",
       " 'width': '2070',\n",
       " 'Dimension ImageOrientation': 'Normal',\n",
       " 'X-TIKA:embedded_resource_path': ['/image3.png',\n",
       "  '/image1.wmf',\n",
       "  '/image2.wmf',\n",
       "  '/_1079260227.unknown',\n",
       "  '/_1079260234.unknown'],\n",
       " 'tiff:ImageWidth': '2070',\n",
       " 'Chroma NumChannels': '3',\n",
       " 'Data SampleFormat': 'Index',\n",
       " 'embeddedRelationshipId': ['_1079260227', '_1079260234'],\n",
       " 'embeddedStorageClassId': ['{0002CE02-0000-0000-C000-000000000046}',\n",
       "  '{0002CE02-0000-0000-C000-000000000046}']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "(\n",
      "Template for Preparation of Papers for IEEE Sponsored Conferences & Symposia\n",
      "\n",
      "Frank Anderson, Sam B. Niles, Jr., and Theodore C. Donald, Member, IEEE\n",
      "Abstract—These instructions give you guidelines for preparing papers for IEEE conferences. Use this document as a template if you are using Microsoft Word 6.0 or later. Otherwise, use this document as an instruction set. Instructions about final paper and figure submissions in this document are for IEEE journals; please use this document as a “template” to prepare your manuscript. For submission guidelines, follow instructions on paper submission system as well as the Conference website. Do not delete the blank line immediately above the abstract; it sets the footnote at the bottom of this column.\n",
      "\n",
      "I. INTRODUCTION\n",
      "T\n",
      "HIS document is a template for Microsoft Word versions 6.0 or later. If you are reading a paper version of this document, please download the electronic file, ieeeconf_letter.dot (for letter sized paper: 8.5” x 11”) or ieeeconf_A4.dot (for A4 sized paper: 210mm x 297mm) and save to MS Word templates directory. The template to produce your conference paper is available at www.paperplaza.net/support/support.html. To create your own document, from within MS Word, open a new document using File | New then select ieeeconf_letter.dot (for letter sized paper) or ieeeconf_A4.dot (for A4 sized paper). All instructions beyond this point are from IEEE. Instructions about final paper and figure submissions in this document are for IEEE journals; please use this document as a “template” to prepare your manuscript. For submission guidelines, follow instructions on paper submission system as well as the Conference website.\n",
      "If your paper is intended for a conference, please contact your conference editor concerning acceptable word processor formats for your particular conference. \n",
      "\n",
      "When you open ieeeconf_letter.doc or ieeeconf_A4.doc, select “Page Layout” from the “View” menu in the menu bar (View | Page Layout), which allows you to see the footnotes. Then type over sections of the sample file, either ieeeconf_letter.doc or ieeeconf_A4.doc or simply cut and paste from another document and then use markup styles. The pull-down style menu is at the left of the Formatting Toolbar at the top of your Word window (for example, the style at this point in the document is “Text”). Highlight a section that you want to designate with a certain style, then select the appropriate name on the style menu. The style will adjust your fonts and line spacing. Do not change the font sizes or line spacing to squeeze more text into a limited number of pages. Use italics for emphasis; do not underline. \n",
      "\n",
      "To insert images in Word, position the cursor at the insertion point and either use Insert | Picture | From File or copy the image to the Windows clipboard and then Edit | Paste Special | Picture (with “Float over text” unchecked). \n",
      "\n",
      "IEEE will do the final formatting of your paper. If your paper is intended for a conference, please observe the conference page limits. \n",
      "\n",
      "II. Procedure for Paper Submission\n",
      "\n",
      "A. Review Stage\n",
      "\n",
      "Instructions about final paper and figure submissions in this document are for IEEE journals; please use this document as a “template” to prepare your manuscript. For submission guidelines, follow instructions on paper submission system as well as the Conference website. Please check with your editor on whether to submit your manuscript by hard copy or electronically for review. If hard copy, submit photocopies such that only one column appears per page. This will give your referees plenty of room to write comments. Send the number of copies specified by your editor (typically four). If submitted electronically, find out if your editor prefers submissions on disk or as e-mail attachments.\n",
      "\n",
      "If you want to submit your file with one column electronically, please do the following:\n",
      "\n",
      "\n",
      "--First, click on the View menu and choose Print Layout.\n",
      "\n",
      "\n",
      "--Second, place your cursor in the first paragraph. Go to the Format menu, choose Columns, choose one column Layout, and choose “apply to whole document” from the dropdown menu.\n",
      "\n",
      "\n",
      "--Third, click and drag the right margin bar to just over 4 inches in width.\n",
      "\n",
      "The graphics will stay in the “second” column, but you can drag them to the first column. Make the graphic wider to push out any text that may try to fill in next to the graphic.\n",
      "\n",
      "B. Final Stage\n",
      "\n",
      "Instructions about final paper and figure submissions in this document are for IEEE journals; please use this document as a “template” to prepare your manuscript. For submission guidelines, follow instructions on paper submission system as well as the Conference website. When you submit your final version, after your paper has been accepted, print it in two-column format, including figures and tables. Send three prints of the paper; two will go to IEEE and one will be retained by the Editor-in-Chief or conference publications chair. \n",
      "\n",
      "You must also send your final manuscript on a disk, which IEEE will use to prepare your paper for publication. Write the authors’ names on the disk label. If you are using a Macintosh, please save your file on a PC formatted disk, if possible. You may use Zip or CD-ROM disks for large files, or compress files using Compress, Pkzip, Stuffit, or Gzip. \n",
      "\n",
      "Also send a sheet of paper with complete contact information for all authors. Include full mailing addresses, telephone numbers, fax numbers, and e-mail addresses. This information will be used to send each author a complimentary copy of the journal in which the paper appears. In addition, designate one author as the “corresponding author.” This is the author to whom proofs of the paper will be sent. Proofs are sent to the corresponding author only.\n",
      "\n",
      "C. Figures\n",
      "\n",
      "All tables and figures will be processed as images. However, IEEE cannot extract the tables and figures embedded in your document. (The figures and tables you insert in your document are only to help you gauge the size of your paper, for the convenience of the referees, and to make it easy for you to distribute preprints.) Therefore, submit, on separate sheets of paper, enlarged versions of the tables and figures that appear in your document. These are the images IEEE will scan and publish with your paper. \n",
      "\n",
      "D. Electronic Image Files (Optional)\n",
      "\n",
      "You will have the greatest control over the appearance of your figures if you are able to prepare electronic image files. If you do not have the required computer skills, just submit paper prints as described above and skip this section.\n",
      "\n",
      "1) Easiest Way: If you have a scanner, the best and quickest way to prepare non-color figure files is to print your tables and figures on paper exactly as you want them to appear, scan them, and then save them to a file in PostScript (PS) or Encapsulated PostScript (EPS) formats. Use a separate file for each image. File names should be of the form “fig1.ps” or “fig2.eps.”\n",
      "\n",
      "2) Slightly Harder Way: Using a scanner as above, save the images in TIFF format. High-contrast line figures and tables should be prepared with 600 dpi resolution and saved with no compression, 1 bit per pixel (monochrome), with file names of the form “fig3.tif” or “table1.tif.” To obtain a 3.45-in figure (one-column width) at 600 dpi, the figure requires a horizontal size of 2070 pixels. Typical file sizes will be on the order of 0.5 MB.\n",
      "\n",
      "Photographs and grayscale figures should be prepared with 220 dpi resolution and saved with no compression, 8 bits per pixel (grayscale). To obtain a 3.45-in figure (one-column width) at 220 dpi, the figure should have a horizontal size of 759 pixels. \n",
      "\n",
      "Color figures should be prepared with 400 dpi resolution and saved with no compression, 8 bits per pixel (palette or 256 color). To obtain a 3.45-in figure (one column width) at 400 dpi, the figure should have a horizontal size of 1380 pixels. \n",
      "\n",
      "For more information on TIFF files, please go to http://www.ieee.org/organizations/pubs/transactions/information.htm and click on the link “Guidelines for Author Supplied Electronic Text and Graphics.”\n",
      "\n",
      "3) Somewhat Harder Way: If you do not have a scanner, you may create non-color PostScript figures by “printing” them to files. First, download a PostScript printer driver from http://www.adobe.com/support/downloads/pdrvwin.htm\n",
      "(for Windows) or from\n",
      "\n",
      "http://www.adobe.com/support/downloads/pdrvmac.htm\n",
      "(for Macintosh) and install the “Generic PostScript Printer” definition. In Word, paste your figure into a new document. Print to a file using the PostScript printer driver. File names should be of the form “fig5.ps.” Use Adobe Type 1 fonts when creating your figures, if possible. \n",
      "\n",
      "4) Other Ways: Experienced computer users can convert figures and tables from their original format to TIFF. Some useful image converters are Adobe Photoshop, Corel Draw, and Microsoft Photo Editor, an application that is part of Microsoft Office 97 and Office 2000 (look for C:\\Program Files\\Common Files \\Microsoft Shared\\ PhotoEd\\ PHOTOED.EXE. (You may have to custom-install Photo Editor from your original Office disk.)\n",
      "\n",
      "Here is a way to make TIFF image files of tables. First, create your table in Word. Use horizontal lines but no vertical lines. Hide gridlines (Table | Hide Gridlines). Spell check the table to remove any red underlines that indicate spelling errors. Adjust magnification (View | Zoom) such that you can view the entire table at maximum area when you select View | Full Screen. Move the cursor so that it is out of the way. Press “Print Screen” on your keyboard; this copies the screen image to the Windows clipboard. Open Microsoft Photo Editor and click Edit | Paste as New Image. Crop the table image (click Select button; select the part you want, then Image | Crop). Adjust the properties of the image (File | Properties) to monochrome (1 bit) and 600 pixels per inch. Resize the image (Image | Resize) to a width of 3.45 inches. Save the file (File | Save As) in TIFF with no compression (click “More” button). \n",
      "\n",
      "Most graphing programs allow you to save graphs in TIFF; however, you often have no control over compression or number of bits per pixel. You should open these image files in a program such as Microsoft Photo Editor and re-save them using no compression, either 1 or 8 bits, and either 600 or 220 dpi resolution (File | Properties; Image | Resize). See Section II-D2 for an explanation of number of bits and resolution. If your graphing program cannot export to TIFF, you can use the same technique described for tables in the previous paragraph.\n",
      "\n",
      "A way to convert a figure from Windows Metafile (WMF) to TIFF is to paste it into Microsoft PowerPoint, save it in JPG format, open it with Microsoft Photo Editor or similar converter, and re-save it as TIFF.\n",
      "\n",
      "Microsoft Excel allows you to save spreadsheet charts in Graphics Interchange Format (GIF). To get good resolution, make the Excel charts very large. Then use the “Save as \n",
      "\n",
      "HTML” feature (see http://support.microsoft.com/support/ kb/articles/q158/0/79.asp). You can then convert from GIF to TIFF using Microsoft Photo Editor, for example.\n",
      "\n",
      "No matter how you convert your images, it is a good idea to print the TIFF files to make sure nothing was lost in the conversion. \n",
      "\n",
      "If you modify this document for use with other IEEE journals or conferences, you should save it as type “Word 97-2000 & 6.0/95 - RTF (*.doc)” so that it can be opened by any version of Word.\n",
      "E. Copyright Form\n",
      "\n",
      "An IEEE copyright form should accompany your final submission. These will be custom generated for you at the submission time. Authors are responsible for obtaining any security clearances.\n",
      "\n",
      "III. MATH\n",
      "If you are using Word, use either the Microsoft Equation Editor or the MathType add-on (http://www.mathtype.com) for equations in your paper (Insert | Object | Create New | Microsoft Equation or MathType Equation). “Float over text” should not be selected. \n",
      "\n",
      "IV. Units\n",
      "\n",
      "Use either SI (MKS) or CGS as primary units. (SI units are strongly encouraged.) English units may be used as secondary units (in parentheses). This applies to papers in data storage. For example, write “15 Gb/cm2 (100 Gb/in2).” An exception is when English units are used as identifiers in trade, such as “3½ in disk drive.” Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity in an equation.\n",
      "\n",
      "The SI unit for magnetic field strength H is A/m. However, if you wish to use units of T, either refer to magnetic flux density B or magnetic field strength symbolized as µ0H. Use the center dot to separate compound units, e.g., “A·m2.”\n",
      "\n",
      "V. Helpful Hints\n",
      "\n",
      "A. Figures and Tables\n",
      "\n",
      "Instructions about final paper and figure submissions in this document are for IEEE journals; please use this document as a “template” to prepare your manuscript. For submission guidelines, follow instructions on paper submission system as well as the Conference website. Because IEEE will do the final formatting of your paper, you do not need to position figures and tables at the top and bottom of each column. In fact, all figures, figure captions, and tables can be at the end of the paper. Large figures and tables may span both columns. Place figure captions below the figures; place table titles above the tables. If your figure has two parts, include the labels “(a)” and “(b)” as part of the artwork. Please verify that the figures and tables you mention in the text actually exist. Please do not include captions as part of the figures. Do not put captions in “text boxes” linked to the figures. Do not put borders around the outside of your figures. Use the abbreviation “Fig.” even at the beginning of a sentence. Do not abbreviate “Table.” Tables are numbered with Roman numerals. \n",
      "\n",
      "Color printing of figures is available, but is billed to the authors (approximately $1300, depending on the number of figures and number of pages containing color). Include a note with your final paper indicating that you request color printing. Do not use color unless it is necessary for the proper interpretation of your figures. If you want reprints of your color article, the reprint order should be submitted promptly. There is an additional charge of $81 per 100 for color reprints.\n",
      "\n",
      "Figure axis labels are often a source of confusion. Use words rather than symbols. As an example, write the quantity “Magnetization,” or “Magnetization M,” not just “M.” Put units in parentheses. Do not label axes only with units. As in Fig. 1, for example, write “Magnetization (A/m)” or “Magnetization (A\n",
      "m(1),” not just “A/m.” Do not label axes with a ratio of quantities and units. For example, write “Temperature (K),” not “Temperature/K.” \n",
      "\n",
      "Multipliers can be especially confusing. Write “Magnetization (kA/m)” or “Magnetization (103 A/m).” Do not write “Magnetization (A/m) ( 1000” because the reader would not know whether the top axis label in Fig. 1 meant 16000 A/m or 0.016 A/m. Figure labels should be legible, approximately 8 to 12 point type.\n",
      "\n",
      "B. References\n",
      "\n",
      "Number citations consecutively in square brackets [1]. The sentence punctuation follows the brackets [2]. Multiple references [2], [3] are each numbered with separate brackets [1]–[3]. When citing a section in a book, please give the relevant page numbers [2]. In sentences, refer simply to the reference number, as in [3]. Do not use “Ref. [3]” or “reference [3]” except at the beginning of a sentence: “Reference [3] shows ... .” Unfortunately the IEEE document translator cannot handle automatic endnotes in Word; therefore, type the reference list at the end of the paper using the “References” style.\n",
      "\n",
      "Number footnotes separately in superscripts (Insert | Footnote).\n",
      " Place the actual footnote at the bottom of the column in which it is cited; do not put footnotes in the reference list (endnotes). Use letters for table footnotes (see Table I). \n",
      "\n",
      "Please note that the references at the end of this document are in the preferred referencing style. Give all authors’ names; do not use “et al.” unless there are six authors or more. Use a space after authors' initials. Papers that have not been published should be cited as “unpublished” [4]. Papers that have been submitted for publication should be cited as “submitted for publication” [5]. Papers that have been accepted for publication, but not yet specified for an issue should be cited as “to be published” [6]. Please give affiliations and addresses for private communications [7].\n",
      "\n",
      "Capitalize only the first word in a paper title, except for proper nouns and element symbols. If you are short of space, you may omit paper titles. However, paper titles are helpful to your readers and are strongly recommended. For papers published in translation journals, please give the English citation first, followed by the original foreign-language citation [8].\n",
      "\n",
      "C. Abbreviations and Acronyms\n",
      "\n",
      "Define abbreviations and acronyms the first time they are used in the text, even after they have already been defined in the abstract. Abbreviations such as IEEE, SI, ac, and dc do not have to be defined. Abbreviations that incorporate periods should not have spaces: write “C.N.R.S.,” not “C. N. R. S.” Do not use abbreviations in the title unless they are unavoidable (for example, “IEEE” in the title of this article).\n",
      "\n",
      "D. Equations\n",
      "\n",
      "Number equations consecutively with equation numbers in parentheses flush with the right margin, as in (1). First use the equation editor to create the equation. Then select the “Equation” markup style. Press the tab key and write the equation number in parentheses. To make your equations more compact, you may use the solidus ( / ), the exp function, or appropriate exponents. Use parentheses to avoid ambiguities in denominators. Punctuate equations when they are part of a sentence, as in\n",
      "\n",
      "\n",
      "(1)\n",
      "\n",
      "Be sure that the symbols in your equation have been defined before the equation appears or immediately following. Italicize symbols (T might refer to temperature, but T is the unit tesla). Refer to “(1),” not “Eq. (1)” or “equation (1),” except at the beginning of a sentence: “Equation (1) is ... .”\n",
      "\n",
      "E. Other Recommendations\n",
      "\n",
      "Use one space after periods and colons. Hyphenate complex modifiers: “zero-field-cooled magnetization.” Avoid dangling participles, such as, “Using (1), the potential was calculated.” [It is not clear who or what used (1).] Write instead, “The potential was calculated by using (1),” or “Using (1), we calculated the potential.”\n",
      "\n",
      "Use a zero before decimal points: “0.25,” not “.25.” Use “cm3,” not “cc.” Indicate sample dimensions as “0.1 cm ( 0.2 cm,” not “0.1 ( 0.2 cm2.” The abbreviation for “seconds” is “s,” not “sec.” Do not mix complete spellings and abbreviations of units: use “Wb/m2” or “webers per square meter,” not “webers/m2.” When expressing a range of values, write “7 to 9” or “7-9,” not “7~9.”\n",
      "\n",
      "A parenthetical statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.) In American English, periods and commas are within quotation marks, like “this period.” Other punctuation is “outside”! Avoid contractions; for example, write “do not” instead of “don’t.” The serial comma is preferred: “A, B, and C” instead of “A, B and C.”\n",
      "\n",
      "If you wish, you may write in the first person singular or plural and use the active voice (“I observed that ...” or “We observed that ...” instead of “It was observed that ...”). Remember to check spelling. If your native language is not English, please get a native English-speaking colleague to proofread your paper. \n",
      "\n",
      "VI. Some Common Mistakes\n",
      "\n",
      "The word “data” is plural, not singular. The subscript for the permeability of vacuum µ0 is zero, not a lowercase letter “o.” The term for residual magnetization is “remanence”; the adjective is “remanent”; do not write “remnance” or “remnant.” Use the word “micrometer” instead of “micron.” A graph within a graph is an “inset,” not an “insert.” The word “alternatively” is preferred to the word “alternately” (unless you really mean something that alternates). Use the word “whereas” instead of “while” (unless you are referring to simultaneous events). Do not use the word “essentially” to mean “approximately” or “effectively.” Do not use the word “issue” as a euphemism for “problem.” When compositions are not specified, separate chemical symbols by en-dashes; for example, “NiMn” indicates the intermetallic compound Ni0.5Mn0.5 whereas “Ni–Mn” indicates an alloy of some composition NixMn1-x.\n",
      "\n",
      "Be aware of the different meanings of the homophones “affect” (usually a verb) and “effect” (usually a noun), “complement” and “compliment,” “discreet” and “discrete,” “principal” (e.g., “principal investigator”) and “principle” (e.g., “principle of measurement”). Do not confuse “imply” and “infer.” \n",
      "\n",
      "Prefixes such as “non,” “sub,” “micro,” “multi,” and “\"ultra” are not independent words; they should be joined to the words they modify, usually without a hyphen. There is no period after the “et” in the Latin abbreviation “et al.” (it is also italicized). The abbreviation “i.e.,” means “that is,” and the abbreviation “e.g.,” means “for example” (these abbreviations are not italicized).\n",
      "\n",
      "An excellent style manual and source of information for science writers is [9]. A general IEEE style guide, Information for Authors, is available at http://www.ieee.org/organizations/pubs/transactions/information.htm\n",
      "VII. Editorial Policy\n",
      "\n",
      "Submission of a manuscript is not required for participation in a conference. Do not submit a reworked version of a paper you have submitted or published elsewhere. Do not publish “preliminary” data or results. The submitting author is responsible for obtaining agreement of all coauthors and any consent required from sponsors before submitting a paper. IEEE TRANSACTIONS and JOURNALS strongly discourage courtesy authorship. It is the obligation of the authors to cite relevant prior work.\n",
      "\n",
      "The Transactions and Journals Department does not publish conference records or proceedings. The TRANSACTIONS does publish papers related to conferences that have been recommended for publication on the basis of peer review. As a matter of convenience and service to the technical community, these topical papers are collected and published in one issue of the TRANSACTIONS.\n",
      "At least two reviews are required for every paper submitted. For conference-related papers, the decision to accept or reject a paper is made by the conference editors and publications committee; the recommendations of the referees are advisory only. Undecipherable English is a valid reason for rejection. Authors of rejected papers may revise and resubmit them to the TRANSACTIONS as regular papers, whereupon they will be reviewed by two new referees.\n",
      "\n",
      "VIII. Publication Principles\n",
      "\n",
      "The contents of IEEE TRANSACTIONS and JOURNALS are peer-reviewed and archival. The TRANSACTIONS publishes scholarly articles of archival value as well as tutorial expositions and critical reviews of classical subjects and topics of current interest. \n",
      "\n",
      "Authors should consider the following points:\n",
      "\n",
      "1) Technical papers submitted for publication must advance the state of knowledge and must cite relevant prior work. \n",
      "\n",
      "2) The length of a submitted paper should be commensurate with the importance, or appropriate to the complexity, of the work. For example, an obvious extension of previously published work might not be appropriate for publication or might be adequately treated in just a few pages.\n",
      "\n",
      "3) Authors must convince both peer reviewers and the editors of the scientific and technical merit of a paper; the standards of proof are higher when extraordinary or unexpected results are reported. \n",
      "\n",
      "4) Because replication is required for scientific progress, papers submitted for publication must provide sufficient information to allow readers to perform similar experiments or calculations and use the reported results. Although not everything need be disclosed, a paper must contain new, useable, and fully described information. For example, a specimen's chemical composition need not be reported if the main purpose of a paper is to introduce a new measurement technique. Authors should expect to be challenged by reviewers if the results are not supported by adequate data and critical details.\n",
      "\n",
      "5) Papers that describe ongoing work or announce the latest technical achievement, which are suitable for presentation at a professional conference, may not be appropriate for publication in a TRANSACTIONS or JOURNAL.\n",
      "IX. Conclusion\n",
      "\n",
      "A conclusion section is not required. Although a conclusion may review the main points of the paper, do not replicate the abstract as the conclusion. A conclusion might elaborate on the importance of the work or suggest applications and extensions. \n",
      "\n",
      "Appendix\n",
      "\n",
      "Appendixes, if needed, appear before the acknowledg-ment.\n",
      "\n",
      "Acknowledgment\n",
      "\n",
      "The preferred spelling of the word “acknowledgment” in American English is without an “e” after the “g.” Use the singular heading even if you have many acknowledgments. Avoid expressions such as “One of us (S.B.A.) would like to thank ... .” Instead, write “F. A. Author thanks ... .” Sponsor and financial support acknowledgments are placed in the unnumbered footnote on the first page.\n",
      "\n",
      "References\n",
      "\n",
      "[1] G. O. Young, “Synthetic structure of industrial plastics (Book style with paper title and editor),” \n",
      "in Plastics, 2nd ed. vol. 3, J. Peters, Ed.  New York: McGraw-Hill, 1964, pp. 15–64.\n",
      "\n",
      "[2] W.-K. Chen, Linear Networks and Systems (Book style).\n",
      "Belmont, CA: Wadsworth, 1993, pp. 123–135.\n",
      "\n",
      "[3] \n",
      "H. Poor, An Introduction to Signal Detection and Estimation.   New York: Springer-Verlag, 1985, ch. 4.\n",
      "\n",
      "[4] B. Smith, “An approach to graphs of linear forms (Unpublished work style),” unpublished.\n",
      "\n",
      "[5] E. H. Miller, “A note on reflector arrays (Periodical style—Accepted for publication),” IEEE Trans. Antennas Propagat., to be published.\n",
      "\n",
      "[6] J. Wang, “Fundamentals of erbium-doped fiber amplifiers arrays (Periodical style—Submitted for publication),” IEEE J. Quantum Electron., submitted for publication.\n",
      "\n",
      "[7] C. J. Kaufman, Rocky Mountain Research Lab., Boulder, CO, private communication, May 1995.\n",
      "\n",
      "[8] Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, “Electron spectroscopy studies on magneto-optical media and plastic substrate interfaces(Translation Journals style),” IEEE Transl. J. Magn.Jpn., vol. 2, Aug. 1987, pp. 740–741 [Dig. 9th Annu. Conf. Magnetics Japan, 1982, p. 301].\n",
      "\n",
      "[9] M. Young, The Techincal Writers Handbook.  Mill Valley, CA: University Science, 1989.\n",
      "\n",
      "[10] J. U. Duncombe, “Infrared navigation—Part I: An assessment of feasibility (Periodical style),” IEEE Trans. Electron Devices, vol. ED-11, pp. 34–39, Jan. 1959.\n",
      "\n",
      "[11] \n",
      "S. Chen, B. Mulgrew, and P. M. Grant, “A clustering technique for digital communications channel equalization using radial basis function networks,” IEEE Trans. Neural Networks, vol. 4, pp. 570–578, July 1993.\n",
      "\n",
      "[12] R. W. Lucky, “Automatic equalization for digital communication,” Bell Syst. Tech. J., vol. 44, no. 4, pp. 547–588, Apr. 1965.\n",
      "\n",
      "[13] S. P. Bingulac, “On the compatibility of adaptive controllers (Published Conference Proceedings style),” in Proc. 4th Annu. Allerton Conf. Circuits and Systems Theory, New York, 1994, pp. 8–16.\n",
      "\n",
      "[14] G. R. Faulhaber, “Design of service systems with priority reservation,” in Conf. Rec. 1995 IEEE Int. Conf. Communications, pp. 3–8.\n",
      "\n",
      "[15] W. D. Doyle, “Magnetization reversal in films with biaxial anisotropy,” in 1987 Proc. INTERMAG Conf., pp. 2.2-1–2.2-6.\n",
      "\n",
      "[16] G. W. Juette and L. E. Zeffanella, “Radio noise currents n short sections on bundle conductors (Presented Conference Paper style),” presented at the IEEE Summer power Meeting, Dallas, TX, June 22–27, 1990, Paper 90 SM 690-0 PWRS.\n",
      "[17] J. G. Kreifeldt, “An analysis of surface-detected EMG as an amplitude-modulated noise,” presented at the 1989 Int. Conf. Medicine and Biological Engineering, Chicago, IL.\n",
      "\n",
      "[18] J. Williams, “Narrow-band analyzer (Thesis or Dissertation style),” Ph.D. dissertation, Dept. Elect. Eng., Harvard Univ., Cambridge, MA, 1993. \n",
      "\n",
      "[19] N. Kawasaki, “Parametric study of thermal and chemical nonequilibrium nozzle flow,” M.S. thesis, Dept. Electron. Eng., Osaka Univ., Osaka, Japan, 1993.\n",
      "\n",
      "[20] J. P. Wilkinson, “Nonlinear resonant circuit devices (Patent style),” U.S. Patent 3 624 12, July 16, 1990. \n",
      "\n",
      "[21] IEEE Criteria for Class IE Electric Systems (Standards style), IEEE Standard 308, 1969.\n",
      "\n",
      "[22] Letter Symbols for Quantities, ANSI Standard Y10.5-1968.\n",
      "\n",
      "[23] R. E. Haskell and C. T. Case, “Transient signal propagation in lossless isotropic plasmas (Report style),” USAF Cambridge Res. Lab., Cambridge, MA Rep. ARCRL-66-234 (II), 1994, vol. 2.\n",
      "\n",
      "[24] E. E. Reber, R. L. Michell, and C. J. Carter, “Oxygen absorption in the Earth’s atmosphere,” Aerospace Corp., Los Angeles, CA, Tech. Rep. TR-0200 (420-46)-3, Nov. 1988.\n",
      "\n",
      "[25] (Handbook style) Transmission Systems for Communications, 3rd ed., Western Electric Co., Winston-Salem, NC, 1985, pp. 44–60.\n",
      "Motorola Semiconductor Data Manual, Motorola Semiconductor Products Inc., Phoenix, AZ, 1989.\n",
      "\n",
      "[26] (Basic Book/Monograph Online Sources) J. K. Author. (year, month, day). Title (edition) [Type of medium]. Volume(issue).\n",
      " Available: http://www.(URL)\n",
      "\n",
      "[27] J. Jones. (1991, May 10). Networks (2nd ed.) [Online]. Available: http://www.atm.com\n",
      "[28] (Journal Online Sources style) K. Author. (year, month). Title. Journal [Type of medium]. Volume(issue), paging if given.\n",
      "  Available: http://www.(URL)\n",
      "\n",
      "[29] R. J. Vidmar. (1992, August). On the use of atmospheric plasmas as electromagnetic reflectors. IEEE Trans. Plasma Sci. [Online]. 21(3). pp. 876—880.   Available: http://www.halcyon.com/pub/journals/ 21ps03-vidmar\n",
      "\n",
      "TABLE I\n",
      "\n",
      "Units for Magnetic Properties\n",
      "\n",
      "Symbol�\n",
      "Quantity�\n",
      "Conversion from Gaussian and\n",
      "\n",
      "CGS EMU to SI a�\n",
      "�\n",
      "(�\n",
      "magnetic flux�\n",
      "1 Mx ( 10(8 Wb = 10(8 V·s�\n",
      "�\n",
      "B�\n",
      "magnetic flux density, \n",
      "\n",
      "  magnetic induction�\n",
      "1 G ( 10(4 T = 10(4 Wb/m2�\n",
      "�\n",
      "H�\n",
      "magnetic field strength�\n",
      "1 Oe ( 103/(4() A/m�\n",
      "�\n",
      "m�\n",
      "magnetic moment�\n",
      "1 erg/G = 1 emu \n",
      "\n",
      "  ( 10(3 A·m2 = 10(3 J/T�\n",
      "�\n",
      "M�\n",
      "magnetization�\n",
      "1 erg/(G·cm3) = 1 emu/cm3\n",
      "\n",
      "  ( 103 A/m�\n",
      "�\n",
      "4(M�\n",
      "magnetization�\n",
      "1 G ( 103/(4() A/m�\n",
      "�\n",
      "(�\n",
      "specific magnetization�\n",
      "1 erg/(G·g) = 1 emu/g ( 1 A·m2/kg�\n",
      "�\n",
      "j�\n",
      "magnetic dipole \n",
      "\n",
      "  moment�\n",
      "1 erg/G = 1 emu \n",
      "\n",
      "  ( 4( ( 10(10 Wb·m�\n",
      "�\n",
      "J�\n",
      "magnetic polarization�\n",
      "1 erg/(G·cm3) = 1 emu/cm3\n",
      "\n",
      "  ( 4( ( 10(4 T�\n",
      "�\n",
      "(, (�\n",
      "susceptibility�\n",
      "1 ( 4(�\n",
      "�\n",
      "((�\n",
      "mass susceptibility�\n",
      "1 cm3/g ( 4( ( 10(3 m3/kg�\n",
      "�\n",
      "(�\n",
      "permeability�\n",
      "1 ( 4( ( 10(7 H/m \n",
      "\n",
      "  = 4( ( 10(7 Wb/(A·m)�\n",
      "�\n",
      "(r�\n",
      "relative permeability�\n",
      "( ( (r�\n",
      "�\n",
      "w, W�\n",
      "energy density�\n",
      "1 erg/cm3 ( 10(1 J/m3�\n",
      "�\n",
      "N, D�\n",
      "demagnetizing factor�\n",
      "1 ( 1/(4()�\n",
      "�\n",
      "No vertical lines in table. Statements that serve as captions for the entire table do not need footnote letters. \n",
      "\n",
      "aGaussian units are the same as cgs emu for magnetostatics; Mx = maxwell, G = gauss, Oe = oersted; Wb = weber, V = volt, s = second, T = tesla, m = meter, A = ampere, J = joule, kg = kilogram, H = henry.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "�\n",
      "\n",
      "Fig. 1.  Magnetization as a function of applied field. Note that “Fig.” is abbreviated. There is a period after the figure number, followed by two spaces. It is good practice to explain the significance of the figure in the caption.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This work was supported in part by the U.S. Depart�ment of Com�merce under Grant BS123456 (sponsor and financial support acknowledgment goes here). Paper titles should be written in uppercase and lowercase letters, not all uppercase. Avoid writing long formulas with subscripts in the title; short formulas that identify the elements are fine (e.g., \"Nd–Fe–B\"). Do not write \"(Invited)\" in the title. Full names of authors are preferred in the author field, but are not required. Put a space between authors' initials. \n",
      "\n",
      "F. Anderson is with the National Institute of Standards and Technology, Boulder, CO 80305 USA (corresponding author to provide phone: 303-555-5555; fax: 303-555-5555; e-mail: author@ boulder.nist.gov). \n",
      "\n",
      "S. B. Niles, Jr., was with Rice University, Houston, TX 77005 USA. He is now with the Department of Physics, Colorado State University, Fort Collins, CO 80523 USA (e-mail: author@lamar. colostate.edu).\n",
      "\n",
      "T. C. Donald is with the Electrical Engineering Department, University of Colorado, Boulder, CO 80309 USA, on leave from the National Research Institute for Metals, Tsukuba, Japan (e-mail: author@nrim.go.jp).\n",
      "\n",
      "�It is recommended that footnotes be avoided (except for the unnumbered footnote with the receipt date on the first page). Instead, try to integrate the footnote information into the text.\n",
      "\n",
      "\n",
      "\n",
      "_1079260227.unknown\n",
      "\n",
      "_1079260234.unknown\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "e\n",
      "e\n",
      "7 a\n",
      "\n",
      "co\n",
      "—\n",
      "\n",
      "| | | | |\n",
      "wv N >) fe @) c a N )\n",
      "- - -\n",
      "\n",
      "(U/W) Uoeznoubey\\\n",
      "\n",
      "Applied Field (104 A/m)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "×\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      ")\n",
      "(\n",
      ")\n",
      "(\n",
      ")\n",
      "|\n",
      "|\n",
      "(\n",
      "exp\n",
      ")]\n",
      "2\n",
      "(\n",
      "/\n",
      "[\n",
      ")\n",
      ",\n",
      "(\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "m\n",
      "s\n",
      "j\n",
      "j\n",
      "d\n",
      "r\n",
      "J\n",
      "r\n",
      "J\n",
      "z\n",
      "z\n",
      "r\n",
      "d\n",
      "dr\n",
      "r\n",
      "F\n",
      "i\n",
      "i\n",
      "j\n",
      "r\n",
      "-\n",
      "¥\n",
      "-\n",
      "-\n",
      "×\n",
      "=\n",
      "ò\n",
      "ò\n",
      "\n",
      "Parsing sample.pdf...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pdf:unmappedUnicodeCharsPerPage': ['0', '0', '0', '0', '0'],\n",
       " 'pdf:PDFVersion': '1.4',\n",
       " 'xmp:CreatorTool': 'wkhtmltopdf 0.12.6',\n",
       " 'pdf:hasXFA': 'false',\n",
       " 'access_permission:modify_annotations': 'true',\n",
       " 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.pdf.PDFParser'],\n",
       " 'X-TIKA:content_handler': 'ToTextContentHandler',\n",
       " 'pdf:num3DAnnotations': '0',\n",
       " 'dcterms:created': '2025-05-27T04:03:59Z',\n",
       " 'dc:format': 'application/pdf; version=1.4',\n",
       " 'pdf:docinfo:creator_tool': 'wkhtmltopdf 0.12.6',\n",
       " 'pdf:overallPercentageUnmappedUnicodeChars': '0.0',\n",
       " 'access_permission:fill_in_form': 'true',\n",
       " 'pdf:hasCollection': 'false',\n",
       " 'pdf:encrypted': 'false',\n",
       " 'pdf:containsNonEmbeddedFont': 'false',\n",
       " 'Content-Length': '141241',\n",
       " 'pdf:hasMarkedContent': 'false',\n",
       " 'pdf:ocrPageCount': '0',\n",
       " 'Content-Type': 'application/pdf',\n",
       " 'access_permission:can_print_faithful': 'true',\n",
       " 'pdf:producer': 'Qt 4.8.7',\n",
       " 'pdf:totalUnmappedUnicodeChars': '0',\n",
       " 'access_permission:extract_for_accessibility': 'true',\n",
       " 'access_permission:assemble_document': 'true',\n",
       " 'xmpTPg:NPages': '5',\n",
       " 'resourceName': \"b'sample.pdf'\",\n",
       " 'pdf:hasXMP': 'false',\n",
       " 'pdf:charsPerPage': ['1735', '1560', '1547', '705', '658'],\n",
       " 'access_permission:extract_content': 'true',\n",
       " 'access_permission:can_print': 'true',\n",
       " 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.pdf.PDFParser'],\n",
       " 'X-TIKA:parse_time_millis': '81',\n",
       " 'X-TIKA:embedded_depth': '0',\n",
       " 'pdf:annotationTypes': 'null',\n",
       " 'access_permission:can_modify': 'true',\n",
       " 'pdf:docinfo:producer': 'Qt 4.8.7',\n",
       " 'pdf:docinfo:created': '2025-05-27T04:03:59Z',\n",
       " 'pdf:annotationSubtypes': 'Link',\n",
       " 'pdf:containsDamagedFont': 'false'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "홍성규\n",
      " +82 10 7233 1952  hsung951027@gmail.com\n",
      "\n",
      "안녕하세요. Ops 엔지니어로써 커리어를 이어가고 있는 홍성규입니다. NLP Researcher로 1년, MLOps Engineer로서 2년으로 총 \n",
      "3년 엔지니어로서의 경험이 있습니다. 클라우드와 온프레미스 환경에서 쿠버네티스 클러스터 운영 경험이 있으며, 기술에 대해 왜라는 질\n",
      "문을 던지고 그에 따른 답을 도출하기 위해 깊은 고민을 합니다.\n",
      "\n",
      "인공지능 분야에서 커리어를 시작했지만, DevOps의 애플리케이션과 인프라 경계를 허무는 철학과 문화에 깊은 매력을 느껴 Ops 엔지\n",
      "니어로 전향하게 되었습니다. 개발과 운영의 협업을 통해 SDLC 전반의 효율성과 품질을 높이고, 팀 간의 소통과 책임을 강화하는 문화를 \n",
      "지향합니다. 아래는 운영 경험을 통해 얻은 주요 인사이트입니다.\n",
      "\n",
      "- 리서처로서 가설을 세우고 실험에 집중하는 과정에서, 연구 개발한 알고리즘이 실제 서비스로 제공되어야 진정한 의미가 있다고 느꼈습\n",
      "니다. 단순히 백엔드 개발에 그치지 않고, 전체 운영 사이클을 직접 구현함으로써 사용자 경험을 보다 세밀하게 개선할 수 있다는 점에서 \n",
      "DevOps의 매력을 발견했습니다.\n",
      "- 반복적인 비생산성 업무를 자동화하고, 개발자와 운영자 사이의 커뮤니케이션 병목을 제거하는 환경이 비즈니스 로직에 집중할 수 있는 \n",
      "기반임을 깨달았습니다. 자동화는 작업 효율을 극대화하고, 빠른 피드백과 문제 해결을 가능하게 합니다.\n",
      "- 재해 복구 파이프라인을 구축하며 24/7 가용성을 확보했고, 이를 통해 동료와 고객, 비즈니스에 대한 신뢰성을 높일 수 있었습니다. 안\n",
      "정적인 운영은 DevOps의 핵심 가치 중 하나입니다.\n",
      "- 안정적인 운영의 지속성을 위해서는 관리에 대한 기술적 오버헤드뿐만 아니라 비용, 러닝 커브 등 제약 사항들을 고려하는 과정속에서 \n",
      "현실성 있는 엔지니어링을 경험해볼 수 있었습니다.\n",
      "- 아직 대규모 마이크로서비스 운영 경험은 없지만, 서비스가 확장될 때 Zero-trust 기반의 mTLS 인증 등 보안을 강화하는 Istio 서비스\n",
      "메시 네트워크에 큰 관심을 갖고 있습니다. 애플리케이션과 인프라 레이어의 디커플링을 통해 비즈니스 로직의 의존성을 줄이는 패턴은 \n",
      "단일 책임 원칙을 연상케 했습니다.\n",
      "\n",
      "이러한 경험과 깨달음을 바탕으로, DevOps 영역에서 전문성을 확장하며 외부 고객뿐만 아니라 협업하는 동료 엔지니어에게도 신뢰받는\n",
      "엔지니어로 성장해 나가고자 합니다. 또한, 기술뿐 아니라, 팀과 조직의 소통·협업 문화를 혁신하는 데 있다는 점을 항상 염두에 두고 있습\n",
      "니다.\n",
      "\n",
      "경력 3년 1개월\n",
      "\n",
      "주식회사포자랩스 \n",
      "2023.07 - 재직 중   (1년 11개월)  정규직  MLOps Engineer\n",
      "AWS Summit Music Project\n",
      "2025.03 - 2025.04\n",
      "- 2025 AWS Summit 행사의 SageMaker HyperPod 도입 고객 사례 제공\n",
      "- AWS HyperPod 전담팀과 커뮤니케이션을 통해 학습환경 마이그레이션\n",
      "- 기존 온프레미스 환경 대비 LLM 분산 학습 시간 2-3배 단축 (Llama 3 1B 기준)\n",
      "\n",
      "셀프 서비스 아키텍처\n",
      "2025.01 - 2025.05\n",
      "- 개발자들이 개발에 필요한 클라우드 리소스를 스스로 프로비저닝할 수 있도록 지원\n",
      "- 슬랙 워크플로우 및 Typer CLI 애플리케이션과 boto3를 추상화한 백엔드 서버 구축\n",
      "- Lambda Function 프로비저닝, CF Invalidation, Bedrock Knowledge Flow 계정간 마이그레이션 기능 제공\n",
      "- 개발자와 운영자 사이의 커뮤니케이션 병목 완화\n",
      "\n",
      "\n",
      "\n",
      "DR 파이프라인\n",
      "2024.12 - 2025.03\n",
      "- 인공지능 API 장애 발생시 Active-Active 서버리스 재해 복구 파이프라인 구성\n",
      "- 서버리스 스택(EventBridge, Step Functions, Lambda) CI/CD 구성 및 Terragrunt 프로비저닝을 통해 운영 오버헤드 감소\n",
      "- 초기 Airflow DAG로 구성한 워크플로 대비 99% Probing 시간 절감 (23분 -> 2초)\n",
      "\n",
      "분산형 모니터링 시스템\n",
      "2024.09 - 2024.12\n",
      "- Helm Chart를 이용한 온프레미스 클러스터 별 Promtaill, Prometheus 스택 구축\n",
      "- VPC Endpoint, Site-to-Site VPN를 이용한 사내 중앙 관리 AWS 계정 프라이빗 통신망 구성\n",
      "- 모니터링 결과 분석을 통한 데이터 전송 비용 70% 절감 (일일 1500GB -> 500GB)\n",
      "\n",
      "분산 학습 플랫폼\n",
      "2024.06 - 2024.09\n",
      "- Kubeflow를 이용한 분산 학습 플랫폼 제공\n",
      "- React TypeScript, FastAPI를 이용하여 분산 학습 기능 구축 및 Kubeflow 통합 (Training Operator 추상화)\n",
      "- 연구자들이 코드 레벨에서 모델 학습 코드 및 데이터에만 집중하도록 환경 제공\n",
      "\n",
      "CI/CD 파이프라인\n",
      "2024.03 - 2024.12\n",
      "- 생성형 인공지능 API 서빙을 목적으로 GitOps CI/CD 파이프라인 구성\n",
      "- ARC, ArgoCD를 이용하여 모델 서버 배포 파이프라인 구성\n",
      "- Redis Lock을 통해 병렬로 빌드하는 과정에서 충돌 현상 해결\n",
      "- torch 이미지와 비즈니스 로직 이미지를 격리하여 소스코드 변경에 대한 빌드 시간 감소 (emptyDir 활용)\n",
      "- 빌드시간 4배 이상 단축 (20분 -> 5분)\n",
      "\n",
      "인공지능 API 아키텍처\n",
      "2024.01 - 2024.12\n",
      "- 자사 서비스(https://www.eapy.io/en, https://www.laive.io/)의 중앙 MIDI 음원 생성 시스템\n",
      "- 사내 음원 생성 시스템의 인공지능 API의 아키텍처 및 백엔드 서버 구성\n",
      "- 모놀로식 아키텍처에서 모델별로 격리된 MSA 아키텍처로 디커플링\n",
      "- Kafka 클러스터 및 Redis 도입 (비동기 음원 생성 API 구현)\n",
      "- Vault 도입 및 API Key를 통한 미들웨어에서의 인증과정 도입\n",
      "- KEDA 도입을 통해 fine-grained 오토스케일링 구성\n",
      "\n",
      "하이브리드 쿠버네티스 환경 도입\n",
      "2023.09 - 2024.02\n",
      "- 온프레미스 K8s와 장애에 대비한 EKS 클러스터를 하이브리드 형태로 구축 (Active-Active)\n",
      "- IaC(Terraform, Terragrunt)를 적용하여 요구사항에 맞게 EKS 모듈을 새로 정의하고 프로비저닝\n",
      "- Site-to-Site VPN 및 VPC Endpoint 적용하여 Private Networking 구현\n",
      "- 클러스터 내 GPU 리소스 부족에 대응하도록 Karpenter 오토스케일러 적용 (+ Consolidation)\n",
      "- 초기 인프라 구조 대비 클러스터 수 및 비용 감소 (3개 -> 1개)\n",
      "\n",
      "주식회사미스테리코 \n",
      "2022.05 - 2023.04   (1년)  정규직  Data Scientist\n",
      "병렬 텍스트 임베더 구현\n",
      "2023.03 - 2023.04\n",
      "\n",
      "\n",
      "\n",
      "- FastAPI, multiprocessing 모듈을 사용하여 자연어 문장들을 병렬로 임베딩하는 파이프라인 구성\n",
      "- Batch 확장에 대한 한계를 극복하기 위해 Multi-GPU 환경에서 BERT 임베딩 모델 수평 스케일링 목적\n",
      "- Spawning한 프로세스 수만큼 선형적으로 임베딩 시간 절약\n",
      "\n",
      "SetFit을 활용한 카테고리 모델 서버 개선\n",
      "2023.03 - 2023.04\n",
      "- 모놀리식 카테고리 분류기 서버를 카테고리별 MSA 형태로 디커플링\n",
      "- SetFit 모델 적용을 통한 Few-shot learning 적용\n",
      "- 학습 데이터에 대해 EDA 진행 및 편향 제거\n",
      "- F1-Score : 0.9 (레거시 모델 대비 1/2 양의 학습 데이터로 달성)\n",
      "\n",
      "이상치 문서 요약\n",
      "2023.02 - 2023.03\n",
      "- 자사 스크래핑 시스템에서 수집된 이상치로 분류된 문서 요약기 서버 구현 및 배포\n",
      "- OpenAI GPT-3.5 (text-davinci-003) 모델을 통해 text summarization 태스크 수행\n",
      "- 연산 비용 최적화를 위해 동일한 프롬프트에 대한 생성 결과 Redis 캐싱\n",
      "\n",
      "트렌드 어구 추출\n",
      "2023.01 - 2023.03\n",
      "- 자사 서비스의 트렌드 키워드(화두가 되는 키워드) 추출 알고리즘 고도화\n",
      "- 새로운 트렌드 점수 수식 모델링을 통해 서브워드 단위 추출에서 고유명사 및 출현 빈도를 고려한 어구 단위 추출로 변경 (Clickhouse\n",
      "DW에 정렬 수식 적용)\n",
      "- Kiwi 형태소 분석기 적용 및 연속적으로 출현한 명사 토큰들을 조합하여 유의미한 어구를 추출 (e.g. ʻ맥도날드’ 키워드 중심으로 ʻ경희\n",
      "대 쥐다리튀김ʻ 추출)\n",
      "\n",
      "Polyglot (GPTNeoX) Prefix-tuning을 통한 챗봇 구현\n",
      "2023.01 - 2023.01\n",
      "- 자사 서비스에 챗봇을 도입하기 위한 연구 및 검증 진행\n",
      "- Polyglot 모델을 통한 NLG (Natural Language Generation) 태스크 수행\n",
      "- 학습 과정에서 Distributed Data Parallelism, Model Parallelism 연구 및 적용\n",
      "\n",
      "Instagram Spam Image Classifier 모델링\n",
      "2022.10 - 2022.11\n",
      "- 선정적인 이미지를 필터링하기 위한 ViT 기반의 분류 모델 학습\n",
      "- \"AN IMAGE IS WORTH 16 X 16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\" 논문 참고\n",
      "- 이미지 라벨링 도구 스크래치 구성\n",
      "\n",
      "서브워드 토큰 NER & ABSA 모델링\n",
      "2022.11 - 2023.04\n",
      "- 문장 단위가 아닌 토크나이저로 분리된 서브워드 토큰 단위로 문맥을 고려하여 감정 및 개체명 분류기 서버 구성 및 배포 (전후처리 파\n",
      "이프라인, 모델)\n",
      "- 학습 속도 및 전체 문맥 파악 능력 향상을 위해 ElectraForTokenClassification 적용\n",
      "- ABSA : 자연어 전처리 플랫폼 Doccano를 통해 약 5천건의 데이터 레이블링, F1-Score : 0.79\n",
      "- NER : 셀렉트스타로부터 데이터 바우처 사업을 통해 약 8만건의 데이터 수령, F1-Score : 0.89\n",
      "\n",
      "주식회사솔트룩스 \n",
      "2020.03 - 2020.04   (2개월)  인턴\n",
      "\n",
      "\n",
      "\n",
      "인턴 교육\n",
      "2020.03 - 2020.04\n",
      "- 약 2개월간 플랫폼 사업 본부에서 챗봇 개발 인턴\n",
      "- 기초 자연어처리 교육 이수 및 챗봇 기획 구현 프로젝트 수행\n",
      "\n",
      "학력\n",
      "\n",
      "국민대학교 소프트웨어융합대학원\n",
      "2021.03 - 2022.08  졸업  인공지능 전공\n",
      "- 논문 및 저널 투고\n",
      "• STFT와 시계열 데이터 이미지화 알고리즘을 활용한 시계열 데이터 분류 성능 분석, 2022.07.14, 국민대학교 성곡도서관\n",
      "• 사전학습 BERT 기반 미세 조정 기법별 감정 분류 성능 평가, 2022.08.10, 한국통신학회\n",
      "\n",
      "한경대학교\n",
      "2014.03 - 2020.11  졸업  컴퓨터 공학과\n",
      "- CS (운영체제 / 네트워크 / 데이터베이스 / 프로그래밍 언어 / 알고리즘 / 자료구조 .. ) 강의 이수\n",
      "- 졸업 프로젝트 진행 (E-편한꿀잠 : Arduino & Android 활용)\n",
      "\n",
      "스킬\n",
      "\n",
      "PyTorch   Python   Docker   FastAPI   NLP   Kubernetes   Redis   AWS   Terraform\n",
      "\n",
      "Prometheus   Grafana   Apache Airflow   Apache Kafka\n",
      "\n",
      "수상/자격증/기타\n",
      "AWS Solutions Architect Professional\n",
      "2024.12   자격증\n",
      "Amazon Web Services\n",
      "\n",
      "AWS Certified Cloud Practitioner\n",
      "2021.05   자격증\n",
      "Amazon Web Services\n",
      "\n",
      "정보처리기사\n",
      "\n",
      "2019.10   자격증\n",
      "QNet\n",
      "\n",
      "\n",
      "\n",
      "가짜연구소 5기\n",
      "2022.09   교육\n",
      "Season 5 : “이미지와 한글이 만나면 어떨까“ 팀 소속 러너\n",
      "Multi-Modal Generation Model에 대한 논문 및 코드 리\n",
      "뷰\n",
      "\n",
      "- VQA (VQA: Visual Question Answering)\n",
      "- Auto Encoder, Variational Auto Encoder\n",
      "- VQ-VAE (Neural Discrete Representation Learning\n",
      ")\n",
      "- DALL-E (Zero-Shot Text-to-Image Generation)\n",
      "\n",
      "딥러닝 기술을 이용한 영상처리 응용 프로젝트 개발\n",
      "2019.11   교육\n",
      "한성대 X SBA \"딥러닝을 활용한 영상처리 프로젝트\"\n",
      "\n",
      "- 기초 딥러닝 강의 이수 및 \"Deep learning을 활용한 CCTV\n",
      "도로객체 인식\" 프로젝트 진행\n",
      "- YOLO v2 네트워크를 활용하여 CCTV 영상속 객체 검출 및 \n",
      "특정 상황 인지\n",
      "- multi object tracker 활용하여 YOLO의 연산량 5배 단축\n",
      "\n",
      "링크\n",
      "\n",
      "노션 포트폴리오\n",
      "https://www.notion.so/About-ME-c0daf222e12643fab701dfae182a3c21?pvs=4\n",
      "\n",
      "깃허브 링크\n",
      "https://github.com/Ryu0n\n",
      "\n",
      "링크드인 링크\n",
      "https://www.linkedin.com/in/sung-kyu-hong-792832243/\n",
      "\n",
      "https://www.notion.so/About-ME-c0daf222e12643fab701dfae182a3c21?pvs=4\n",
      "https://github.com/Ryu0n\n",
      "https://www.linkedin.com/in/sung-kyu-hong-792832243/\n",
      "\n",
      "\t홍성규\n",
      "\t경력 3년 1개월\n",
      "\tAWS Summit Music Project\n",
      "\t셀프 서비스 아키텍처\n",
      "\tDR 파이프라인\n",
      "\t분산형 모니터링 시스템\n",
      "\t분산 학습 플랫폼\n",
      "\tCI/CD 파이프라인\n",
      "\t인공지능 API 아키텍처\n",
      "\t하이브리드 쿠버네티스 환경 도입\n",
      "\t병렬 텍스트 임베더 구현\n",
      "\tSetFit을 활용한 카테고리 모델 서버 개선\n",
      "\t이상치 문서 요약\n",
      "\t트렌드 어구 추출\n",
      "\tPolyglot (GPTNeoX) Prefix-tuning을 통한 챗봇 구현\n",
      "\tInstagram Spam Image Classifier 모델링\n",
      "\t서브워드 토큰 NER & ABSA 모델링\n",
      "\t인턴 교육\n",
      "\n",
      "\t학력\n",
      "\t국민대학교 소프트웨어융합대학원\n",
      "\t한경대학교\n",
      "\n",
      "\t스킬\n",
      "\t수상/자격증/기타\n",
      "\tAWS Solutions Architect Professional\n",
      "\tAWS Certified Cloud Practitioner\n",
      "\t정보처리기사\n",
      "\t가짜연구소 5기\n",
      "\t딥러닝 기술을 이용한 영상처리 응용 프로젝트 개발\n",
      "\n",
      "\t링크\n",
      "\t노션 포트폴리오\n",
      "\t깃허브 링크\n",
      "\t링크드인 링크\n",
      "\n",
      "Parsing sample.hwp...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w:Comments': '',\n",
       " 'dc:subject': '',\n",
       " 'meta:last-author': '지현',\n",
       " 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.hwp.HwpV5Parser'],\n",
       " 'X-TIKA:content_handler': 'ToTextContentHandler',\n",
       " 'dc:creator': '지현',\n",
       " 'resourceName': \"b'sample.hwp'\",\n",
       " 'dcterms:created': '2022-11-09T21:14:21Z',\n",
       " 'dcterms:modified': '2022-11-09T21:39:47Z',\n",
       " 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.hwp.HwpV5Parser'],\n",
       " 'dc:title': '나를 소개 합니다',\n",
       " 'meta:keyword': '',\n",
       " 'X-TIKA:parse_time_millis': '4',\n",
       " 'X-TIKA:embedded_depth': '0',\n",
       " 'cp:subject': '',\n",
       " 'Content-Length': '10752',\n",
       " 'meta:page-count': '0',\n",
       " 'Content-Type': 'application/x-hwp-v5'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나를 소개 합니다\n",
      "\n",
      "나를 소개 합니다 \n",
      "\n",
      "① 이름 :  \n",
      "\n",
      " 혈액형 : O형 \n",
      "\n",
      " 성격 : 자유로운 영혼 \n",
      "\n",
      " 좌우명 : A sound mind in a sound body. \n",
      "\n",
      " 소개하는 글 \n",
      "\n",
      "어린 시절은 변두리 작은 동네에서 꿈 많은 소녀로 자라났습니다. 할머니, 할아버지, 삼촌들까지 대가족 속에서 막내로 귀여움을 받으면서 살았습니다. 가족들은 저에게 微笑天使라고 부르곤 했습니다. 가족들의 사랑 덕분에 잘 자라날 수 있었습니다. \n",
      "\n",
      "현재 저는 사랑하는 아이들과 남편과 함께 행복(幸福)한 삶을 살아가고 있습니다. 앞으로의 꿈은 아이들이 결혼하고 나면 남편과 시골에서 조그마한 텃밭을 가꾸면서 살아가는 것입니다. 그 꿈을 실현할 수 있기를 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "for e in ext:\n",
    "    file_name = f\"sample.{e}\"\n",
    "    print(f\"\\nParsing {file_name}...\")\n",
    "    parse(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
